{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43c1a77-b308-4747-9dd3-8161415d0542",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Monte Carlo Tree Search\n",
    "\n",
    "In this lab, we'll be using the game connect four, as a vehicle for learning Monte Carlo Tree Search.\n",
    "We'll also introduce concepts, such as state, that'll stay throughout the course.\n",
    "Expect to lose to the algorithm at the end of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df728ba-bb09-419c-80c6-3e42863c9322",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This section you won't need to edit, but it is worth skimming throughâ€”this is we declare the objects you'll be interacting with througout the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6afed3e-4274-42f2-baf7-fd808e967e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "from copy import deepcopy # world -> world model\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32942bc4-a6cf-4485-8b47-4e3618bc8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# world and world model\n",
    "class State:\n",
    "    def __init__(self, cols=7, rows=6, win_req=4):\n",
    "        self.board = [['.'] * cols for _ in range(rows)]\n",
    "        self.heights = [0] * cols\n",
    "        self.num_moves = 0\n",
    "        self.win_req = win_req\n",
    "        self.winner = None\n",
    "        \n",
    "    def get_actions(self) -> List[int]:\n",
    "        return [i for i in range(len(self.board[0])) if self.heights[i] < len(self.board)]\n",
    "    \n",
    "    def __str__(self):\n",
    "        header  = \" \".join([str(i) for i in range(len(self.board[0]))])\n",
    "        line    = \"\".join([\"-\" for _ in range(len(header))])\n",
    "        board   = [[e for e in row] for row in self.board]\n",
    "        board   = '\\n'.join([' '.join(row) for row in board])\n",
    "        return  '\\n' + header + '\\n' + line + '\\n' + board + '\\n'\n",
    "    \n",
    "    def detect_winner(self):\n",
    "        pass\n",
    "        \n",
    "    def get_action(self, action):\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0714c81-77e3-44b9-a05a-a8611ac73427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parrent class for mcts, minmax, human, and any other idea for an agent you have\n",
    "class Agent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name: str = name\n",
    "    \n",
    "    def give_action(self, state: State):\n",
    "        return random.choice(state.get_actions())\n",
    "    \n",
    "    def utility(self, state: State):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb42b607-098c-41f5-a3dd-c5d44311c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting states and agents\n",
    "class Game:\n",
    "    def __init__(self, agents: Tuple[Agent]):\n",
    "        self.agents = agents\n",
    "        self.state = State()\n",
    "\n",
    "    def play(self):\n",
    "        while True:\n",
    "            for agent in agents:\n",
    "                if not self.state.winner:\n",
    "                    agent.give_action(self.state)\n",
    "                    print(self.state)\n",
    "                    break\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a8a5f-ca01-4c07-bf57-22d94ab91bef",
   "metadata": {},
   "source": [
    "## Exercise 0: Run game\n",
    "put the state, agent and game class together so that a game is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795cdddb-c33f-4310-ac20-0f5abd3409d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agents = (Agent('O'), Agent('X'))\n",
    "game = Game(agents)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377f998-91ca-4641-8307-e64c8be93491",
   "metadata": {},
   "source": [
    "## Exercise 1: Human Agent\n",
    "Make a child class of `Agent` called `Human`, with the `give_action` method overwritten to take input from you. *hint*: use `int(input())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2649620-9f2f-4f6a-8e57-9f216a3c3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Human(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(Human, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fa6b2-e265-4cf0-8017-8369d4a15fef",
   "metadata": {},
   "source": [
    "## Exercise 2: Gekko\n",
    "Make a child class of `Agent` called `Gekko`, with the `give_action` that is as short sighted as you can possibly make it. Here you'll need to edit both `give_action`, `utility`, and perhaps some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b999e09-dde6-41db-8222-a7d63803d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Gekko(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(Gekko, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574aa66-6bca-4c99-9834-fe96f3a39992",
   "metadata": {},
   "source": [
    "## Exercise 3: MinMax\n",
    "Make a MinMax agent, using the the minmax heuristic. Have it play against another copy of itself.\n",
    "Make a version of MinMax tat uses Alpha Beta pruning. Sort the action space so as to make this as useful as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59084465-4bb9-472d-bc7f-74fefd64942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MinMax(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(MinMax, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f8df2-09ff-4e43-872a-f402d01f3ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 4: & Alpha Beta pruning\n",
    "Same but for Monte Carlo Tree Search. See if you can beat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4872464f-9c71-4627-a463-c51976cca202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MCTS(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(MCTS, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb1506-bff6-46b6-a05b-3c26a7e3ad26",
   "metadata": {},
   "source": [
    "## Exercise 5: MCTS\n",
    "Same but for Monte Carlo Tree Search. See if you can beat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49ace487-bcc3-43df-ae5b-424f17cb4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MCTS(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(MCTS, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0037a71-a406-4c89-bf88-4b22eb53a135",
   "metadata": {},
   "source": [
    "## Exercise 6 (optional): Dynamic Programming\n",
    "Then use dynamic programming to make your AI more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81433732-cc21-4dff-84e4-85857c3910ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgs",
   "language": "python",
   "name": "dlgs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
