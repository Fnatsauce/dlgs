{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43c1a77-b308-4747-9dd3-8161415d0542",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Monte Carlo Tree Search\n",
    "\n",
    "In this lab, we'll be using the game connect four, as a vehicle for learning MinMax and Monte Carlo Tree Search.\n",
    "We'll also introduce concepts, such as state, that'll stay relevant throughout the course.\n",
    "Expect to lose in connect four to the algorithm at the end of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df728ba-bb09-419c-80c6-3e42863c9322",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This section you won't need to edit, but it is worth skimming throughâ€”this is where we declare the objects you'll be interacting with througout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6afed3e-4274-42f2-baf7-fd808e967e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import time\n",
    "from copy import deepcopy # world -> world model\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32942bc4-a6cf-4485-8b47-4e3618bc8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# world and world model\n",
    "class State:\n",
    "    def __init__(self, cols=7, rows=6, win_req=4):\n",
    "        self.board = [['.'] * cols for _ in range(rows)]\n",
    "        self.heights = [0] * cols\n",
    "        self.num_moves = 0\n",
    "        self.win_req = win_req\n",
    "        self.winner = None\n",
    "        \n",
    "    def get_avail_actions(self) -> List[int]:\n",
    "        return [i for i in range(len(self.board[0])) if self.heights[i] < len(self.board)]\n",
    "  \n",
    "    def put_action(self, action, agent):\n",
    "        self.board[self.heights[action]][action] = agent.name\n",
    "        self.heights[action] += 1\n",
    "        self.num_moves += 1\n",
    "        self.detect_winner()\n",
    "        \n",
    "    def is_over(self):\n",
    "        return self.num_moves < len(self.board) * len(self.board[0])\n",
    "        \n",
    "    def detect_winner(self):\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        header  = \" \".join([str(i) for i in range(len(self.board[0]))])\n",
    "        line    = \"\".join([\"-\" for _ in range(len(header))])\n",
    "        board   = [[e for e in row] for row in self.board]\n",
    "        board   = '\\n'.join([' '.join(row) for row in board])\n",
    "        return  '\\n' + header + '\\n' + line + '\\n' + board + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f0714c81-77e3-44b9-a05a-a8611ac73427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parrent class for mcts, minmax, human, and any other idea for an agent you have\n",
    "class Agent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name: str = name\n",
    "    \n",
    "    def get_action(self, state: State):\n",
    "        return random.choice(state.get_avail_actions())\n",
    "    \n",
    "    def utility(self, state: State):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eb42b607-098c-41f5-a3dd-c5d44311c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting states and agents\n",
    "class Game:\n",
    "    def __init__(self, agents: Tuple[Agent]):\n",
    "        self.agents = agents\n",
    "        self.state = State()\n",
    "\n",
    "    def play(self):\n",
    "        while not self.state.is_over():\n",
    "            for agent in agents:\n",
    "                if not self.state.is_over():\n",
    "                    action = agent.get_action(self.state)\n",
    "                    self.state.put_action(action, agent)\n",
    "                    time.sleep(0.1)\n",
    "                    print(self.state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a8a5f-ca01-4c07-bf57-22d94ab91bef",
   "metadata": {},
   "source": [
    "## Exercise 0: Discuss and Run game\n",
    "Let's discuss if the `utility` function best belongs to the state or the agent.\n",
    "Put the state, agent and game class together so that a game is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "795cdddb-c33f-4310-ac20-0f5abd3409d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/4kbgmth52mbg2gmw426yh9000000gn/T/ipykernel_70734/2755938108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5n/4kbgmth52mbg2gmw426yh9000000gn/T/ipykernel_70734/2699582898.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5n/4kbgmth52mbg2gmw426yh9000000gn/T/ipykernel_70734/3859782993.py\u001b[0m in \u001b[0;36mis_over\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_moves\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetect_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agents = (Agent('O'), Agent('X'))\n",
    "game = Game(agents)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377f998-91ca-4641-8307-e64c8be93491",
   "metadata": {},
   "source": [
    "## Exercise 1: Human Agent\n",
    "Make a child class of `Agent` called `Human`, with the `give_action` method overwritten to take input from you. *hint*: use `int(input())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d2649620-9f2f-4f6a-8e57-9f216a3c3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Human(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(Human, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fa6b2-e265-4cf0-8017-8369d4a15fef",
   "metadata": {},
   "source": [
    "## Exercise 2: Gekko\n",
    "Make a child class of `Agent` called `Gekko`, with the `give_action` that is as short sighted as you can possibly make it. Here you'll need to edit both `give_action`, `utility`, and perhaps some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b999e09-dde6-41db-8222-a7d63803d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Gekko(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(Gekko, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574aa66-6bca-4c99-9834-fe96f3a39992",
   "metadata": {},
   "source": [
    "## Exercise 3: MinMax\n",
    "Make a MinMax agent, using the the minmax heuristic. Have it play against another copy of itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "59084465-4bb9-472d-bc7f-74fefd64942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MinMax(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(MinMax, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f8df2-09ff-4e43-872a-f402d01f3ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 4: & Alpha Beta pruning\n",
    "Make a version of MinMax tat uses Alpha Beta pruning. Sort the action space so as to make this as useful as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4872464f-9c71-4627-a463-c51976cca202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MinMaxAB(MinMax):\n",
    "#    def __init__(self):\n",
    "#        super(MinMaxAB, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb1506-bff6-46b6-a05b-3c26a7e3ad26",
   "metadata": {},
   "source": [
    "## Exercise 5: MCTS\n",
    "Same but for Monte Carlo Tree Search. See if you can beat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "49ace487-bcc3-43df-ae5b-424f17cb4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MCTS(Agent):\n",
    "#    def __init__(self):\n",
    "#        super(MCTS, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938bcb8-abc6-4b76-b188-55250e068a15",
   "metadata": {},
   "source": [
    "## Exercise 6: Simulations\n",
    "Make a function that runs a bunch of simulations of differnt agents playing eachother, and see how often each win. Plot it in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "04789366-2408-40a5-9ad7-f1f9a9c12fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate(a_bunch=100):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0037a71-a406-4c89-bf88-4b22eb53a135",
   "metadata": {},
   "source": [
    "## Optional exercise: Dynamic Programming\n",
    "Then use dynamic programming to make your AI more efficient. You can use the class below (or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81433732-cc21-4dff-84e4-85857c3910ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranspositionTable:\n",
    "\n",
    "    def __init__(self, size=1_000_000):\n",
    "        self.size = size\n",
    "        self.vals = [None] * size\n",
    "\n",
    "    def board_str(self, state: State):\n",
    "        return ''.join([''.join(c) for c in state.board])\n",
    "\n",
    "    def put(self, state: State, utility: float):\n",
    "        bstr = self.board_str(state)\n",
    "        idx = hash(bstr) % self.size\n",
    "        self.vals[idx] = (bstr, utility)\n",
    "\n",
    "    def get(self, state: State):\n",
    "        bstr = self.board_str(state)\n",
    "        idx = hash(bstr) % self.size\n",
    "        stored = self.vals[idx]\n",
    "        if stored is None:\n",
    "            return None\n",
    "        if stored[0] == bstr:\n",
    "            return stored[1]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a8fa0-ab56-4401-a4e7-9bec94a58802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgs",
   "language": "python",
   "name": "dlgs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
